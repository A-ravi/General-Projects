import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
df=pd.read_csv('https://github.com/YBI-Foundation/Dataset/raw/main/Bank%20Churn%20Modelling.csv')
df
CustomerId	Surname	CreditScore	Geography	Gender	Age	Tenure	Balance	Num Of Products	Has Credit Card	Is Active Member	Estimated Salary	Churn
0	15634602	Hargrave	619	France	Female	42	2	0.00	1	1	1	101348.88	1
1	15647311	Hill	608	Spain	Female	41	1	83807.86	1	0	1	112542.58	0
2	15619304	Onio	502	France	Female	42	8	159660.80	3	1	0	113931.57	1
3	15701354	Boni	699	France	Female	39	1	0.00	2	0	0	93826.63	0
4	15737888	Mitchell	850	Spain	Female	43	2	125510.82	1	1	1	79084.10	0
...	...	...	...	...	...	...	...	...	...	...	...	...	...
9995	15606229	Obijiaku	771	France	Male	39	5	0.00	2	1	0	96270.64	0
9996	15569892	Johnstone	516	France	Male	35	10	57369.61	1	1	1	101699.77	0
9997	15584532	Liu	709	France	Female	36	7	0.00	1	0	1	42085.58	1
9998	15682355	Sabbatini	772	Germany	Male	42	3	75075.31	2	1	0	92888.52	1
9999	15628319	Walker	792	France	Female	28	4	130142.79	1	1	0	38190.78	0
10000 rows Ã— 13 columns

df.head()
CustomerId	Surname	CreditScore	Geography	Gender	Age	Tenure	Balance	Num Of Products	Has Credit Card	Is Active Member	Estimated Salary	Churn
0	15634602	Hargrave	619	France	Female	42	2	0.00	1	1	1	101348.88	1
1	15647311	Hill	608	Spain	Female	41	1	83807.86	1	0	1	112542.58	0
2	15619304	Onio	502	France	Female	42	8	159660.80	3	1	0	113931.57	1
3	15701354	Boni	699	France	Female	39	1	0.00	2	0	0	93826.63	0
4	15737888	Mitchell	850	Spain	Female	43	2	125510.82	1	1	1	79084.10	0
df.tail()
CustomerId	Surname	CreditScore	Geography	Gender	Age	Tenure	Balance	Num Of Products	Has Credit Card	Is Active Member	Estimated Salary	Churn
9995	15606229	Obijiaku	771	France	Male	39	5	0.00	2	1	0	96270.64	0
9996	15569892	Johnstone	516	France	Male	35	10	57369.61	1	1	1	101699.77	0
9997	15584532	Liu	709	France	Female	36	7	0.00	1	0	1	42085.58	1
9998	15682355	Sabbatini	772	Germany	Male	42	3	75075.31	2	1	0	92888.52	1
9999	15628319	Walker	792	France	Female	28	4	130142.79	1	1	0	38190.78	0
df.info()
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10000 entries, 0 to 9999
Data columns (total 13 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   CustomerId        10000 non-null  int64  
 1   Surname           10000 non-null  object 
 2   CreditScore       10000 non-null  int64  
 3   Geography         10000 non-null  object 
 4   Gender            10000 non-null  object 
 5   Age               10000 non-null  int64  
 6   Tenure            10000 non-null  int64  
 7   Balance           10000 non-null  float64
 8   Num Of Products   10000 non-null  int64  
 9   Has Credit Card   10000 non-null  int64  
 10  Is Active Member  10000 non-null  int64  
 11  Estimated Salary  10000 non-null  float64
 12  Churn             10000 non-null  int64  
dtypes: float64(2), int64(8), object(3)
memory usage: 1015.8+ KB
df.describe()
CustomerId	CreditScore	Age	Tenure	Balance	Num Of Products	Has Credit Card	Is Active Member	Estimated Salary	Churn
count	1.000000e+04	10000.000000	10000.000000	10000.000000	10000.000000	10000.000000	10000.00000	10000.000000	10000.000000	10000.000000
mean	1.569094e+07	650.528800	38.921800	5.012800	76485.889288	1.530200	0.70550	0.515100	100090.239881	0.203700
std	7.193619e+04	96.653299	10.487806	2.892174	62397.405202	0.581654	0.45584	0.499797	57510.492818	0.402769
min	1.556570e+07	350.000000	18.000000	0.000000	0.000000	1.000000	0.00000	0.000000	11.580000	0.000000
25%	1.562853e+07	584.000000	32.000000	3.000000	0.000000	1.000000	0.00000	0.000000	51002.110000	0.000000
50%	1.569074e+07	652.000000	37.000000	5.000000	97198.540000	1.000000	1.00000	1.000000	100193.915000	0.000000
75%	1.575323e+07	718.000000	44.000000	7.000000	127644.240000	2.000000	1.00000	1.000000	149388.247500	0.000000
max	1.581569e+07	850.000000	92.000000	10.000000	250898.090000	4.000000	1.00000	1.000000	199992.480000	1.000000
df.duplicated('CustomerId').sum()
0
df=df.set_index('CustomerId')
df.info()
<class 'pandas.core.frame.DataFrame'>
Int64Index: 10000 entries, 15634602 to 15628319
Data columns (total 12 columns):
 #   Column            Non-Null Count  Dtype  
---  ------            --------------  -----  
 0   Surname           10000 non-null  object 
 1   CreditScore       10000 non-null  int64  
 2   Geography         10000 non-null  object 
 3   Gender            10000 non-null  object 
 4   Age               10000 non-null  int64  
 5   Tenure            10000 non-null  int64  
 6   Balance           10000 non-null  float64
 7   Num Of Products   10000 non-null  int64  
 8   Has Credit Card   10000 non-null  int64  
 9   Is Active Member  10000 non-null  int64  
 10  Estimated Salary  10000 non-null  float64
 11  Churn             10000 non-null  int64  
dtypes: float64(2), int64(7), object(3)
memory usage: 1015.6+ KB
Encoding

df['Geography'].value_counts()
France     5014
Germany    2509
Spain      2477
Name: Geography, dtype: int64
df['Gender'].value_counts()
Male      5457
Female    4543
Name: Gender, dtype: int64
df.replace( { 'Geography' : { 'France':2 , 'Germany': 1 , 'Spain' :0 }},inplace = True )
df['Gender'].value_counts()
Male      5457
Female    4543
Name: Gender, dtype: int64
df.replace( { 'Gender' : { 'Male':0 , 'Female': 1 }},inplace = True )
df['Num Of Products'].value_counts()
1    5084
2    4590
3     266
4      60
Name: Num Of Products, dtype: int64
df.replace( { 'Num Of Products' : { 1:1 , 2: 1, 3 :1 , 4 :1 }},inplace = True )
df['Has Credit Card'].value_counts()
1    7055
0    2945
Name: Has Credit Card, dtype: int64
df['Is Active Member'].value_counts()
1    5151
0    4849
Name: Is Active Member, dtype: int64
df.loc[ (df['Balance']==0),'Churn'].value_counts()
0    3117
1     500
Name: Churn, dtype: int64
df['Zero Balance'] = np.where(df['Balance']>0,1,0)
df['Zero Balance'].hist()
<matplotlib.axes._subplots.AxesSubplot at 0x7f87375b59d0>

df.groupby(['Churn','Geography']).count()
Surname	CreditScore	Gender	Age	Tenure	Balance	Num Of Products	Has Credit Card	Is Active Member	Estimated Salary	Zero Balance
Churn	Geography											
0	0	2064	2064	2064	2064	2064	2064	2064	2064	2064	2064	2064
1	1695	1695	1695	1695	1695	1695	1695	1695	1695	1695	1695
2	4204	4204	4204	4204	4204	4204	4204	4204	4204	4204	4204
1	0	413	413	413	413	413	413	413	413	413	413	413
1	814	814	814	814	814	814	814	814	814	814	814
2	810	810	810	810	810	810	810	810	810	810	810
Define Labels and Features

df.columns
Index(['Surname', 'CreditScore', 'Geography', 'Gender', 'Age', 'Tenure',
       'Balance', 'Num Of Products', 'Has Credit Card', 'Is Active Member',
       'Estimated Salary', 'Churn', 'Zero Balance'],
      dtype='object')
X = df.drop(['Surname','Churn'], axis=1)
y=df['Churn']
X.shape,y.shape
((10000, 11), (10000,))
df['Churn'].value_counts()
0    7963
1    2037
Name: Churn, dtype: int64
sns.countplot(x = 'Churn' , data=df)
<matplotlib.axes._subplots.AxesSubplot at 0x7f87384d2750>

X.shape,y.shape
((10000, 11), (10000,))
from imblearn.under_sampling import RandomUnderSampler
rus =RandomUnderSampler(random_state=242529)
X_rus,y_rus = rus.fit_resample(X,y)
X_rus.shape,y_rus.shape ,X.shape, y.shape
((4074, 11), (4074,), (10000, 11), (10000,))
y.value_counts()
0    7963
1    2037
Name: Churn, dtype: int64
y_rus.value_counts()
0    2037
1    2037
Name: Churn, dtype: int64
y_rus.plot(kind = 'hist')
<matplotlib.axes._subplots.AxesSubplot at 0x7f8735d710d0>

from imblearn.under_sampling import RandomUnderSampler
ros =RandomUnderSampler(random_state=2529)
X_ros,y_ros = ros.fit_resample(X,y)
X_ros.shape,y_ros.shape ,X.shape, y.shape
((4074, 11), (4074,), (10000, 11), (10000,))
y.value_counts()
0    7963
1    2037
Name: Churn, dtype: int64
y_ros.value_counts()
0    2037
1    2037
Name: Churn, dtype: int64
y_ros.plot(kind = 'hist')
<matplotlib.axes._subplots.AxesSubplot at 0x7f8735cfb8d0>

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y ,train_size=0.3 , random_state = 242529)
X_train_rus, X_test_rus, y_train_rus, y_test_rus = train_test_split(X_rus, y_rus ,train_size=0.3 , random_state = 252529)
X_train_ros, X_test_ros, y_train_ros, y_test_ros = train_test_split(X_ros, y_ros ,train_size=0.3 , random_state = 252529)
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_train[['CreditScore','Age','Tenure','Balance','Estimated Salary']])
X_test[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_test[['CreditScore','Age','Tenure','Balance','Estimated Salary']])
X_train_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_train_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']])
X_test_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_test_rus[['CreditScore','Age','Tenure','Balance','Estimated Salary']])
X_train_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_train_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']])
X_test_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']] = sc.fit_transform(X_test_ros[['CreditScore','Age','Tenure','Balance','Estimated Salary']])
from sklearn.svm import SVC
svc = SVC()
svc.fit(X_train,y_train)
SVC()
y_pred = svc.predict(X_test)
from sklearn.metrics import confusion_matrix, classification_report
confusion_matrix(y_test,y_pred)
array([[5515,   60],
       [1174,  251]])
print(classification_report(y_test,y_pred))
              precision    recall  f1-score   support

           0       0.82      0.99      0.90      5575
           1       0.81      0.18      0.29      1425

    accuracy                           0.82      7000
   macro avg       0.82      0.58      0.59      7000
weighted avg       0.82      0.82      0.78      7000

from sklearn.model_selection import GridSearchCV
param_grid  = {
    'C' : [0.1,1,10],
    'gamma' : [1,0.1,0.01] ,
    'kernel':  ['rbf']  ,
    'class_weight':['balanced']  }
grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2, cv=2)
grid.fit(X_train,y_train)
Fitting 2 folds for each of 9 candidates, totalling 18 fits
[CV] END ..C=0.1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.3s
[CV] END ..C=0.1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.3s
[CV] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.3s
[CV] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.3s
[CV] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.3s
[CV] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.3s
[CV] END ....C=1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.3s
[CV] END ....C=1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.3s
[CV] END ..C=1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.2s
[CV] END ..C=1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.2s
[CV] END .C=1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.2s
[CV] END .C=1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.2s
[CV] END ...C=10, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.3s
[CV] END ...C=10, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.3s
[CV] END .C=10, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.2s
[CV] END .C=10, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.2s
[CV] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.2s
[CV] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.2s
GridSearchCV(cv=2, estimator=SVC(),
             param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced'],
                         'gamma': [1, 0.1, 0.01], 'kernel': ['rbf']},
             verbose=2)
print(grid.best_estimator_)
SVC(C=0.1, class_weight='balanced', gamma=1)
grid_predictions = grid.predict(X_test)
confusion_matrix(y_test,grid_predictions)
array([[4920,  655],
       [ 818,  607]])
print(classification_report(y_test,grid_predictions))
              precision    recall  f1-score   support

           0       0.86      0.88      0.87      5575
           1       0.48      0.43      0.45      1425

    accuracy                           0.79      7000
   macro avg       0.67      0.65      0.66      7000
weighted avg       0.78      0.79      0.78      7000

svc_rus = SVC()
svc_rus.fit(X_train_rus,y_train_rus)
SVC()
y_pred_rus = svc_rus.predict(X_test_rus)
confusion_matrix(y_test_rus,y_pred_rus)
array([[1053,  359],
       [ 505,  935]])
print(classification_report(y_test_rus,y_pred_rus))
              precision    recall  f1-score   support

           0       0.68      0.75      0.71      1412
           1       0.72      0.65      0.68      1440

    accuracy                           0.70      2852
   macro avg       0.70      0.70      0.70      2852
weighted avg       0.70      0.70      0.70      2852

param_grid  = {
    'C' : [0.1,1,10],
    'gamma' : [1,0.1,0.01] ,
    'kernel':  ['rbf']  ,
    'class_weight':['balanced']  }
grid_rus = GridSearchCV(SVC(),param_grid,refit=True,verbose=2, cv=2)
grid_rus.fit(X_train_rus,y_train_rus)
Fitting 2 folds for each of 9 candidates, totalling 18 fits
[CV] END ..C=0.1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ..C=0.1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END ....C=1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ....C=1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ..C=1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END ..C=1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END .C=1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END .C=1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END ...C=10, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ...C=10, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END .C=10, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END .C=10, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
GridSearchCV(cv=2, estimator=SVC(),
             param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced'],
                         'gamma': [1, 0.1, 0.01], 'kernel': ['rbf']},
             verbose=2)
print(grid_rus.best_estimator_)
SVC(C=10, class_weight='balanced', gamma=0.01)
grid_predictions_rus = grid_rus.predict(X_test_rus)
confusion_matrix(y_test_rus,grid_predictions_rus)
array([[980, 432],
       [474, 966]])
print(classification_report(y_test_rus,grid_predictions_rus))
              precision    recall  f1-score   support

           0       0.67      0.69      0.68      1412
           1       0.69      0.67      0.68      1440

    accuracy                           0.68      2852
   macro avg       0.68      0.68      0.68      2852
weighted avg       0.68      0.68      0.68      2852

svc_ros = SVC()
svc_ros.fit(X_train_ros,y_train_ros)
SVC()
y_pred_ros = svc_ros.predict(X_test_ros)
confusion_matrix(y_test_ros,y_pred_ros)
array([[1031,  381],
       [ 489,  951]])
print(classification_report(y_test_ros,y_pred_ros))
              precision    recall  f1-score   support

           0       0.68      0.73      0.70      1412
           1       0.71      0.66      0.69      1440

    accuracy                           0.69      2852
   macro avg       0.70      0.70      0.69      2852
weighted avg       0.70      0.69      0.69      2852

param_grid  = {
    'C' : [0.1,1,10],
    'gamma' : [1,0.1,0.01] ,
    'kernel':  ['rbf']  ,
    'class_weight':['balanced']  }
grid_ros = GridSearchCV(SVC(),param_grid,refit=True,verbose=2, cv=2)
grid_ros.fit(X_train_ros,y_train_ros)
Fitting 2 folds for each of 9 candidates, totalling 18 fits
[CV] END ..C=0.1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ..C=0.1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END C=0.1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.1s
[CV] END ....C=1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ....C=1, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ..C=1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.0s
[CV] END ..C=1, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.0s
[CV] END .C=1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END .C=1, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END ...C=10, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END ...C=10, class_weight=balanced, gamma=1, kernel=rbf; total time=   0.1s
[CV] END .C=10, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.0s
[CV] END .C=10, class_weight=balanced, gamma=0.1, kernel=rbf; total time=   0.0s
[CV] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.0s
[CV] END C=10, class_weight=balanced, gamma=0.01, kernel=rbf; total time=   0.0s
GridSearchCV(cv=2, estimator=SVC(),
             param_grid={'C': [0.1, 1, 10], 'class_weight': ['balanced'],
                         'gamma': [1, 0.1, 0.01], 'kernel': ['rbf']},
             verbose=2)
print(grid_ros.best_estimator_)
SVC(C=1, class_weight='balanced', gamma=0.01)
grid_predictions_ros = grid_ros.predict(X_test_ros)
confusion_matrix(y_test_ros,grid_predictions_ros)
array([[1025,  387],
       [ 500,  940]])
print(classification_report(y_test_ros,grid_predictions_ros))
              precision    recall  f1-score   support

           0       0.67      0.73      0.70      1412
           1       0.71      0.65      0.68      1440

    accuracy                           0.69      2852
   macro avg       0.69      0.69      0.69      2852
weighted avg       0.69      0.69      0.69      2852

print(classification_report(y_test,y_pred))
              precision    recall  f1-score   support

           0       0.82      0.99      0.90      5575
           1       0.81      0.18      0.29      1425

    accuracy                           0.82      7000
   macro avg       0.82      0.58      0.59      7000
weighted avg       0.82      0.82      0.78      7000

print(classification_report(y_test,grid_predictions))
              precision    recall  f1-score   support

           0       0.86      0.88      0.87      5575
           1       0.48      0.43      0.45      1425

    accuracy                           0.79      7000
   macro avg       0.67      0.65      0.66      7000
weighted avg       0.78      0.79      0.78      7000

print(classification_report(y_test_rus,y_pred_rus))
              precision    recall  f1-score   support

           0       0.68      0.74      0.71      1412
           1       0.72      0.66      0.69      1440

    accuracy                           0.70      2852
   macro avg       0.70      0.70      0.70      2852
weighted avg       0.70      0.70      0.70      2852

print(classification_report(y_test_ros,grid_predictions_ros))
              precision    recall  f1-score   support

           0       0.67      0.73      0.70      1412
           1       0.71      0.65      0.68      1440

    accuracy                           0.69      2852
   macro avg       0.69      0.69      0.69      2852
weighted avg       0.69      0.69      0.69      2852

